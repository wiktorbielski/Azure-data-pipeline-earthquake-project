{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6983d27b-7bda-45a1-b081-9d5550f7f80e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from datetime import date, timedelta\n",
    "\n",
    "# Remove this before running Data Factory Pipeline\n",
    "start_date = date.today() - timedelta(1)\n",
    "\n",
    "silver_adls = \"abfss://silver@earthquakedataluke.dfs.core.windows.net/\"\n",
    "gold_adls = \"abfss://gold@earthquakedataluke.dfs.core.windows.net/\"\n",
    "\n",
    "silver_data = f\"{silver_adls}earthquake_events_silver/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e91fb293-6bb6-467e-8c4f-ce2d7bc7ec39",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "''' Data Factory\n",
    "\n",
    "import json\n",
    "\n",
    "# Get base parameters\n",
    "dbutils.widgets.text(\"bronze_params\", \"\")\n",
    "dbutils.widgets.text(\"silver_params\", \"\")\n",
    "\n",
    "bronze_params = dbutils.widgets.get(\"bronze_params\")\n",
    "silver_params = dbutils.widgets.get(\"silver_params\")\n",
    "\n",
    "# Debug: Print the raw input values for troubleshooting\n",
    "print(f\"Raw bronze_params: {bronze_params}\")\n",
    "print(f\"Raw silver_params: {silver_params}\")\n",
    "\n",
    "# Parse the JSON string\n",
    "bronze_data = json.loads(bronze_params)\n",
    "\n",
    "# Access individual variables\n",
    "start_date = bronze_data.get(\"start_date\", \"\")\n",
    "end_date = bronze_data.get(\"end_date\", \"\")\n",
    "silver_adls = bronze_data.get(\"silver_adls\", \"\")\n",
    "gold_adls = bronze_data.get(\"gold_adls\", \"\")\n",
    "silver_data = silver_params\n",
    "\n",
    "# Debug: Print the extracted values for verification\n",
    "print(f\"Start Date: {start_date}, End Date: {end_date}\")\n",
    "print(f\"Silver ADLS Path: {silver_adls}, Gold ADLS Path: {gold_adls}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e44e2d7b-08e7-41b0-a110-5f9cc0643077",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, col, udf\n",
    "from pyspark.sql.types import StringType\n",
    "# Ensure the below library is installed on your cluster\n",
    "import reverse_geocoder as rg\n",
    "from datetime import date, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "45dca249-dfb5-4dc8-bd87-f9f0a0eea794",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.parquet(silver_data).filter(col('time') > start_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7bc3fae0-974b-455e-a9c9-8c0ee218fc6e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df.limit(100) # added to speed up processings as during testing it was proving a bottleneck\n",
    "# The problem is caused by the Python UDF (reverse_geocoder) being a bottleneck due to its non-parallel nature and high computational cost per task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c807d0e-1f0f-4113-be4f-414406a7bd4d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_country_code(lat, lon):\n",
    "    \"\"\"\n",
    "    Retrieve the country code for a given latitude and longitude.\n",
    "\n",
    "    Parameters:\n",
    "    lat (float or str): Latitude of the location.\n",
    "    lon (float or str): Longitude of the location.\n",
    "\n",
    "    Returns:\n",
    "    str: Country code of the location, retrieved using the reverse geocoding API.\n",
    "\n",
    "    Example:\n",
    "    >>> get_country_details(48.8588443, 2.2943506)\n",
    "    'FR'\n",
    "    \"\"\"\n",
    "    try:\n",
    "        coordinates = (float(lat), float(lon))\n",
    "        result = rg.search(coordinates)[0].get('cc')\n",
    "        print(f\"Processed coordinates: {coordinates} -> {result}\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing coordinates: {lat}, {lon} -> {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f50a8441-ae75-4ce7-beb5-6329bf365055",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# registering the udfs so they can be used on spark dataframes\n",
    "get_country_code_udf = udf(get_country_code, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a1cfc01-2afa-4c93-839c-55f9553c5b77",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "get_country_code(48.8588443, 2.2943506)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e593bd05-422f-44bb-9848-35a5c317eb81",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# adding country_code and city attributes\n",
    "df_with_location = \\\n",
    "                df.\\\n",
    "                    withColumn(\"country_code\", get_country_code_udf(col(\"latitude\"), col(\"longitude\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f58201f5-2b42-4fab-add5-f6f1d733c6c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c933dd90-30e5-4c69-b61c-ae3ada39f8b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_with_location.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2034f97-d2cd-446a-abfd-6824a549e8b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# adding significance classification\n",
    "df_with_location_sig_class = \\\n",
    "                            df_with_location.\\\n",
    "                                withColumn('sig_class', \n",
    "                                            when(col(\"sig\") < 100, \"Low\").\\\n",
    "                                            when((col(\"sig\") >= 100) & (col(\"sig\") < 500), \"Moderate\").\\\n",
    "                                            otherwise(\"High\")\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1dc0d3e9-e17f-4194-8821-2b3936907c7a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_with_location_sig_class.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04a6b456-4afb-41de-b58e-ca6a6bb93d71",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Save the transformed DataFrame to the Silver container\n",
    "gold_output_path = f\"{gold_adls}earthquake_events_gold/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cbf34037-e51e-4686-bb97-d535c4f29893",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Append DataFrame to Silver container in Parquet format\n",
    "df_with_location_sig_class.write.mode('append').parquet(gold_output_path)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Gold Notebook",
   "widgets": {
    "bronze_params": {
     "currentValue": "",
     "nuid": "c6e65ba2-4002-4950-8d1a-ae2620c79322",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "bronze_params",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "",
      "label": null,
      "name": "bronze_params",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "silver_params": {
     "currentValue": "",
     "nuid": "38805122-0ed7-47d4-90c9-8e3052d9657b",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "silver_params",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "",
      "label": null,
      "name": "silver_params",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
